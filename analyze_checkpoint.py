#!/usr/bin/env python3
"""
Checkpoint Analysis Script
Analyzes the structure of checkpoint files and compares with current model.
"""

import os
import torch
import yaml
from collections import defaultdict
from modelV1 import LatentDiffusion
from audiosr.latent_diffusion.util import instantiate_from_config

def analyze_checkpoint_keys(checkpoint_path):
    """åˆ†ææ£€æŸ¥ç‚¹çš„é”®ç»“æ„"""
    print(f"ğŸ” åˆ†ææ£€æŸ¥ç‚¹: {checkpoint_path}")

    if not os.path.exists(checkpoint_path):
        print("âŒ æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨")
        return

    try:
        ckpt = torch.load(checkpoint_path, map_location='cpu')

        # è·å–state_dict
        if "state_dict" in ckpt:
            state_dict = ckpt["state_dict"]
            print("âœ… ä½¿ç”¨æ£€æŸ¥ç‚¹ä¸­çš„ state_dict")
        elif "ema" in ckpt:
            state_dict = ckpt["ema"]
            print("âœ… ä½¿ç”¨æ£€æŸ¥ç‚¹ä¸­çš„ EMA æƒé‡")
        else:
            state_dict = ckpt
            print("âœ… ä½¿ç”¨æ£€æŸ¥ç‚¹æ ¹çº§åˆ«æƒé‡")

        print(f"ğŸ“Š æ£€æŸ¥ç‚¹ç»Ÿè®¡: {len(state_dict)} ä¸ªé”®")

        # æŒ‰ç»„ä»¶åˆ†ç»„åˆ†æ
        components = defaultdict(list)
        for key in state_dict.keys():
            if "." in key:
                main_component = key.split(".")[0]
                components[main_component].append(key)
            else:
                components["root"].append(key)

        print("\nğŸ—ï¸ æ£€æŸ¥ç‚¹ç»„ä»¶ç»“æ„:")
        for comp, keys in sorted(components.items()):
            print(f"  ğŸ“¦ {comp}: {len(keys)} ä¸ªé”®")
            if len(keys) <= 5:
                for key in keys:
                    print(f"    - {key}")
            else:
                for key in keys[:3]:
                    print(f"    - {key}")
                print(f"    ... è¿˜æœ‰ {len(keys)-3} ä¸ªé”®")

        return state_dict

    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        return None

def analyze_current_model():
    """åˆ†æå½“å‰æ¨¡å‹ç»“æ„"""
    print("\nğŸ” åˆ†æå½“å‰æ¨¡å‹ç»“æ„:")

    try:
        # åŠ è½½é…ç½®
        with open('config.yaml', 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)

        # å®ä¾‹åŒ–æ¨¡å‹
        model = instantiate_from_config(config['model'])
        model_state = model.state_dict()

        print(f"ğŸ“Š å½“å‰æ¨¡å‹ç»Ÿè®¡: {len(model_state)} ä¸ªé”®")

        # æŒ‰ç»„ä»¶åˆ†ç»„åˆ†æ
        components = defaultdict(list)
        for key in model_state.keys():
            if "." in key:
                main_component = key.split(".")[0]
                components[main_component].append(key)
            else:
                components["root"].append(key)

        print("\nğŸ—ï¸ å½“å‰æ¨¡å‹ç»„ä»¶ç»“æ„:")
        for comp, keys in sorted(components.items()):
            print(f"  ğŸ“¦ {comp}: {len(keys)} ä¸ªé”®")
            if len(keys) <= 5:
                for key in keys:
                    print(f"    - {key}")
            else:
                for key in keys[:3]:
                    print(f"    - {key}")
                print(f"    ... è¿˜æœ‰ {len(keys)-3} ä¸ªé”®")

        return model_state

    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆ†æå¤±è´¥: {e}")
        return None

def compare_structures(checkpoint_dict, model_dict):
    """æ¯”è¾ƒæ£€æŸ¥ç‚¹å’Œæ¨¡å‹ç»“æ„"""
    print("\nğŸ” ç»“æ„å¯¹æ¯”åˆ†æ:")

    if checkpoint_dict is None or model_dict is None:
        print("âŒ æ— æ³•è¿›è¡Œå¯¹æ¯”ï¼Œç¼ºå°‘æ•°æ®")
        return

    checkpoint_keys = set(checkpoint_dict.keys())
    model_keys = set(model_dict.keys())

    # è®¡ç®—é‡å å’Œå·®å¼‚
    common_keys = checkpoint_keys & model_keys
    missing_in_checkpoint = model_keys - checkpoint_keys
    unexpected_in_checkpoint = checkpoint_keys - model_keys

    print(f"âœ… å®Œå…¨åŒ¹é…çš„é”®: {len(common_keys)}")
    print(f"âŒ æ£€æŸ¥ç‚¹ä¸­ç¼ºå¤±çš„é”®: {len(missing_in_checkpoint)}")
    print(f"âš ï¸ æ£€æŸ¥ç‚¹ä¸­æ„å¤–çš„é”®: {len(unexpected_in_checkpoint)}")

    if len(missing_in_checkpoint) > 0:
        print(f"\nâŒ ç¼ºå¤±é”®ç¤ºä¾‹ (å‰10ä¸ª):")
        for key in list(missing_in_checkpoint)[:10]:
            print(f"  - {key}")

    if len(unexpected_in_checkpoint) > 0:
        print(f"\nâš ï¸ æ„å¤–é”®ç¤ºä¾‹ (å‰10ä¸ª):")
        for key in list(unexpected_in_checkpoint)[:10]:
            print(f"  - {key}")

    # åˆ†æä¸»è¦ç»„ä»¶çš„åŒ¹é…æƒ…å†µ
    major_components = ["model", "first_stage_model", "cond_stage_models"]

    print(f"\nğŸ” ä¸»è¦ç»„ä»¶åŒ¹é…åˆ†æ:")
    for comp in major_components:
        comp_model_keys = {k for k in model_keys if k.startswith(comp + ".")}
        comp_checkpoint_keys = {k for k in checkpoint_keys if k.startswith(comp + ".")}

        if comp_model_keys and comp_checkpoint_keys:
            match_ratio = len(comp_model_keys & comp_checkpoint_keys) / len(comp_model_keys)
            status = "âœ…" if match_ratio > 0.8 else "âš ï¸" if match_ratio > 0.5 else "âŒ"
            print(f"  {status} {comp}: {match_ratio*100:.1f}% åŒ¹é… ({len(comp_model_keys & comp_checkpoint_keys)}/{len(comp_model_keys)})")
        elif comp_model_keys:
            print(f"  âŒ {comp}: æ£€æŸ¥ç‚¹ä¸­å®Œå…¨ç¼ºå¤± (éœ€è¦ {len(comp_model_keys)} ä¸ªé”®)")
        elif comp_checkpoint_keys:
            print(f"  âš ï¸ {comp}: ä»…åœ¨æ£€æŸ¥ç‚¹ä¸­å­˜åœ¨ ({len(comp_checkpoint_keys)} ä¸ªé”®)")

if __name__ == "__main__":
    # è·å–æ£€æŸ¥ç‚¹è·¯å¾„
    with open('config.yaml', 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)

    checkpoint_path = config['train']['pretrained_path']

    print("=" * 60)
    print("ğŸ”¬ æ£€æŸ¥ç‚¹ä¸æ¨¡å‹ç»“æ„åˆ†æå·¥å…·")
    print("=" * 60)

    # åˆ†ææ£€æŸ¥ç‚¹
    checkpoint_dict = analyze_checkpoint_keys(checkpoint_path)

    # åˆ†æå½“å‰æ¨¡å‹
    model_dict = analyze_current_model()

    # å¯¹æ¯”åˆ†æ
    compare_structures(checkpoint_dict, model_dict)

    print("\n" + "=" * 60)
    print("âœ… åˆ†æå®Œæˆ!")